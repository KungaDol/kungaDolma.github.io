[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my homepage!",
    "section": "",
    "text": "On this website, I will present the projects I completed in the computational statistics class! I hope you enjoy and learn something from it."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "STAT 244-SC",
    "section": "",
    "text": "This project explores transactions from a UK-based online retail store, covering the time frame from December 1, 2010, to December 9, 2011. The store specializes in unique, all-occasion gift items, and the dataset contains over 540,000 rows of transaction data. I found this dataset in https://www.kaggle.com/datasets/carrie1/ecommerce-data.\nThe quantitative variables in this data set are:\n\nQuantity: The number of units of each product purchased. Unit: Count (integer).\nUnitPrice: The price of a single product. Unit: British Pounds Sterling (GBP).\nTotalPrice (we can create this column): The total value of each transaction (Quantity * UnitPrice). Unit: British Pounds Sterling (GBP)   \n\nThe categorical variables present in this dataset are:\n\nDescription: The name or description of the product.\nCountry: The country where the customer resides.\nStock code: The code for each product (item)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my website! I am Kunga Dolma, a senior at Mount Holyoke College majoring in Statistics. I’m originally from Nepal and Tibet, and I celebrate Tibetan Losar, one of my favorite cultural traditions.\nI enjoy reading Webtoons, watching football, and hiking in my free time. My academic and professional interests include sports analytics, marketing, and health data analysis.\nFeel free to Connect with me on LinkedIn"
  },
  {
    "objectID": "project.html#data-visualization",
    "href": "project.html#data-visualization",
    "title": "STAT 244-SC",
    "section": "Data visualization",
    "text": "Data visualization\n\ne_commerce_2011 |&gt;\n  ggplot( aes(x= unit_price)) +\n  geom_density(fill=\"#69b3a2\", color=\"#e9ecef\") + xlim(0,50)\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\nThis density plot of unit price reveals a right-skewed distribution, indicating that most transactions involved low-priced products. The peak occurs between £0 and £5, suggesting that customers—across multiple countries—tend to purchase inexpensive gift items. A smaller number of transactions occur around £10–£20, with very few purchases above £30, and some outliers close to £50. This pattern highlights a general preference for lower-cost products, though a small portion of customers are willing to spend more on select items.\n\nlibrary(forcats)\nggplot(e_commerce_2011, aes(x= fct_infreq(country), y=unit_price)) + \n  geom_bar(stat = \"identity\") + \n   theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nThis bar plot shows the total unit price of purchases across different countries after excluding the United Kingdom. Germany emerges as the highest buyer, followed closely by EIRE (Ireland) and France, suggesting stronger purchasing activity in these regions. On the other end, Portugal shows the lowest total unit price, followed by Finland and Australia, indicating fewer or smaller transactions. This visualization helps highlight regional purchasing trends and emphasizes countries that contribute more significantly to total sales."
  },
  {
    "objectID": "project.html#implementing-the-machine-learning-techniques",
    "href": "project.html#implementing-the-machine-learning-techniques",
    "title": "STAT 244-SC",
    "section": "Implementing the machine learning techniques",
    "text": "Implementing the machine learning techniques\n\nCross Validation (CV)\nCross validation is process of spiting the data into test and training data in order to get a better prediction model. we use k-fold cross-validation to estimate the typical error in our model predictions for new data:\n\nDivide the data into \\(k\\) folds (or groups) of approximately equal size.\n\nRepeat the following procedures for each fold \\(j = 1,2,...,k\\):\n\nRemove fold \\(j\\) from the data set.\n\nFit a model using the data in the other \\(k-1\\) folds (training).\n\nUse this model to predict the responses for the \\(n_j\\) cases in fold \\(j\\): \\(\\hat{y}_1, ..., \\hat{y}_{n_j}\\).\n\nCalculate the MAE for fold \\(j\\) (testing): \\(\\text{MAE}_j = \\frac{1}{n_j}\\sum_{i=1}^{n_j} |y_i - \\hat{y}_i|\\). \\[\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{j=1}^k \\text{MAE}_j\\]\n\n\nThe goal of the use of CV is provide accurate estimate of the model and prevent overfitting. The linear model for this model is:\n\\[\\ Y = \\beta_0(UnitPrice) + \\beta_1(country) + \\beta_2(quantity)\\] \\[\\ Y = \\beta_0(UnitPrice) + \\beta_1(country) + \\beta_2(quantity) + \\beta_3(invoice_date)\\] To implement this CV, we applied 50/50 cross-validation by splitting the dataset (2,653 observations) into a training set of 1,331 and a test set of 1,322. Our chosen error metric is MAE (Mean Absolute Error), defined as: \\(\\text{MAE}_j = \\frac{1}{n_j}\\sum_{i=1}^{n_j} |y_i - \\hat{y}_i|\\)\nWe used MAE to know how well the model is performing by measuring the means of predicted and actual values. This help us evaluate and improve the model in the training stage to get more accurate prediction on new data. The advantage of used of MAE is that it is easy to interpret and understand. It is sensitive to outlier."
  },
  {
    "objectID": "project.html#implement-k-fold-cross-validation-for-k-10.",
    "href": "project.html#implement-k-fold-cross-validation-for-k-10.",
    "title": "STAT 244-SC",
    "section": "Implement k-fold cross validation for k = 10.",
    "text": "Implement k-fold cross validation for k = 10.\n\n# Step 1: Model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  # Output Y is quantitative\n  set_mode(\"regression\") %&gt;%\n  # Want regression to be lienar\n  set_engine(\"lm\")\n\n\ne_commerce_fit &lt;-lm_spec %&gt;% \n  fit(unit_price~country, data = e_commerce_2011)\n\n\ne_commerce_cv %&gt;% collect_metrics()\n\n# A tibble: 3 × 6\n  .metric .estimator     mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard    3.42       10 0.240   Preprocessor1_Model1\n2 rmse    standard   10.4        10 3.25    Preprocessor1_Model1\n3 rsq     standard    0.00504    10 0.00304 Preprocessor1_Model1\n\n\n\nmodel_1 &lt;- lm_spec%&gt;%\n fit(unit_price~country + quantity, data = e_commerce_2011)\n\nmodel_2 &lt;- lm_spec%&gt;%\n fit(unit_price ~ country * quantity+ invoice_date, data =  e_commerce_2011)\n\n\nmodel_1 %&gt;% glance()\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1   0.00970       0.00597  14.1      2.60 0.00390    10 -10821. 21666. 21736.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nmodel_2 %&gt;% glance()\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic    p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0301        0.0228  14.0      4.10    2.57e-9    20 -10793. 21630. 21760.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nmodel_1 %&gt;%\n augment(new_data =e_commerce_2011) %&gt;%\n mae(truth = unit_price, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mae     standard        3.37\n\n\n\nmodel_2 %&gt;%\n augment(new_data = e_commerce_2011) %&gt;%\n mae(truth = unit_price, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mae     standard        3.40\n\n\n\nknitr::opts_chunk$set(cache = TRUE)\n# 10-fold cross-validation for model_2\n set.seed(244)\n model_2_cv&lt;- lm_spec%&gt;%\n   fit_resamples(unit_price ~ country * quantity + invoice_date,\n                  resamples= vfold_cv(e_commerce_2011, v = 10),\n                 metrics = metric_set(mae, rsq)\n )\n\n\nDisplay evaluation metrics for your different models in a clean, organized way. This display should include both the estimated CV metric as well as its standard deviation.\n\n\nmodel_1_cv %&gt;% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   3.41       10 0.239   Preprocessor1_Model1\n2 rsq     standard   0.00497    10 0.00181 Preprocessor1_Model1\n\n\n\nmodel_2_cv %&gt;% collect_metrics()\n\nError in eval(expr, envir, enclos): object 'model_2_cv' not found\n\n\n\nmodel_1_cv %&gt;%\n  unnest(.metrics) %&gt;%\n  dplyr::filter(.metric ==\"mae\") %&gt;%\n  summarize(base::mean(.estimate))\n\n# A tibble: 1 × 1\n  `base::mean(.estimate)`\n                    &lt;dbl&gt;\n1                    3.41\n\n\n\nmodel_2_cv %&gt;%\n  unnest(.metrics) %&gt;%\n  dplyr::filter(.metric ==\"mae\") %&gt;%\n  summarize(base::mean(.estimate))\n\nError in eval(expr, envir, enclos): object 'model_2_cv' not found\n\n\n\nCV: Comparing the models\n\n\n\nModel\nIN-SAMPLE MAE\n10-fold CV MAE\n\n\n\n\nmodel_1\n3.374663\n3.406162\n\n\nmodel_2\n3.400458\n3.464405\n\n\n\nBased on both the in-sample and cross-validation MAE, model_1 performs slightly better. For model_1, the MAE is consistent across training (3.37) and validation (3.41), suggesting that the model generalizes well to new data. In contrast, model_2 has a slightly higher CV MAE (3.46) than its in-sample MAE (3.40), indicating potential overfitting — it may not perform as well on unseen data.\nBased on the in-sample MAE and CV MAE,, model 1 appears to be performing little better. For model 1, it looks like the MAE is consistent it’s measured in sample (3.37) and CV (3.41). However, model 2 seem slightly higher CV MAE (3.46) than in - sample MAE(3.40), suggesting overfitting."
  }
]