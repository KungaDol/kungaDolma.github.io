[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my homepage!",
    "section": "",
    "text": "On this website, I will present the projects I completed in the computational statistics class! I hope you enjoy and learn something from it."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "STAT 244-SC",
    "section": "",
    "text": "This project explores transactions from a UK-based online retail store, covering the time frame from December 1, 2010, to December 9, 2011. The store specializes in unique, all-occasion gift items, and the dataset contains over 540,000 rows of transaction data. I found this dataset in https://www.kaggle.com/datasets/carrie1/ecommerce-data.\nThe quantitative variables in this data set are:\n\nQuantity: The number of units of each product purchased. Unit: Count (integer).\nUnitPrice: The price of a single product. Unit: British Pounds Sterling (GBP).\nTotalPrice (we can create this column): The total value of each transaction (Quantity * UnitPrice). Unit: British Pounds Sterling (GBP)   \n\nThe categorical variables present in this dataset are:\n\nDescription: The name or description of the product.\nCountry: The country where the customer resides.\nStock code: The code for each product (item)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my website! I am Kunga Dolma, a senior at Mount Holyoke College majoring in Statistics. I’m originally from Nepal and Tibet, and I celebrate Tibetan Losar, one of my favorite cultural traditions.\nI enjoy reading Webtoons, watching football, and hiking in my free time. My academic and professional interests include sports analytics, marketing, and health data analysis.\nFeel free to Connect with me on LinkedIn"
  },
  {
    "objectID": "project.html#data-visualization",
    "href": "project.html#data-visualization",
    "title": "STAT 244-SC",
    "section": "Data visualization",
    "text": "Data visualization\n\ne_commerce_2011 |&gt;\n  ggplot( aes(x= unit_price)) +\n  geom_density(fill=\"#69b3a2\", color=\"#e9ecef\") + xlim(0,50)+\n  labs(\n    title = \"Density Plot of unit price\",\n    x = \"Unit Price \",\n    y = \"Density\"\n  ) +\n  theme_minimal()\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\nThis density plot of unit price reveals a right-skewed distribution, indicating that most transactions involved low-priced products. The peak occurs between £0 and £5, suggesting that customers—across multiple countries—tend to purchase inexpensive gift items. A smaller number of transactions occur around £10–£20, with very few purchases above £30, and some outliers close to £50. This pattern highlights a general preference for lower-cost products, though a small portion of customers are willing to spend more on select items.\n\nlibrary(forcats)\nggplot(e_commerce_2011, aes(x= fct_infreq(country), y=unit_price)) + \n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Bar plot of Unit Price & Country\",\n    x = \"Country\",\n    y = \"Unit Price \"\n  ) +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nThis bar plot shows the total unit price of purchases across different countries after excluding the United Kingdom. Germany emerges as the highest buyer, followed closely by EIRE (Ireland) and France, suggesting stronger purchasing activity in these regions. On the other end, Portugal shows the lowest total unit price, followed by Finland and Australia, indicating fewer or smaller transactions. This visualization helps highlight regional purchasing trends and emphasizes countries that contribute more significantly to total sales."
  },
  {
    "objectID": "project.html#implementing-the-machine-learning-techniques",
    "href": "project.html#implementing-the-machine-learning-techniques",
    "title": "STAT 244-SC",
    "section": "Implementing the machine learning techniques",
    "text": "Implementing the machine learning techniques\n\nCross Validation (CV)\nCross validation is process of spiting the data into test and training data in order to get a better prediction model. we use k-fold cross-validation to estimate the typical error in our model predictions for new data:\n\nDivide the data into \\(k\\) folds (or groups) of approximately equal size.\n\nRepeat the following procedures for each fold \\(j = 1,2,...,k\\):\n\nRemove fold \\(j\\) from the data set.\n\nFit a model using the data in the other \\(k-1\\) folds (training).\n\nUse this model to predict the responses for the \\(n_j\\) cases in fold \\(j\\): \\(\\hat{y}_1, ..., \\hat{y}_{n_j}\\).\n\nCalculate the MAE for fold \\(j\\) (testing): \\(\\text{MAE}_j = \\frac{1}{n_j}\\sum_{i=1}^{n_j} |y_i - \\hat{y}_i|\\). \\[\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{j=1}^k \\text{MAE}_j\\]\n\n\nThe goal of the use of CV is provide accurate estimate of the model and prevent overfitting. The linear model for this model is:\n\\[\\ Y = \\beta_0(UnitPrice) + \\beta_1(country) + \\beta_2(quantity)\\] \\[\\ Y = \\beta_0(UnitPrice) + \\beta_1(country) + \\beta_2(quantity) + \\beta_3(invoice_date)\\] To implement this CV, we applied 50/50 cross-validation by splitting the dataset (2,653 observations) into a training set of 1,331 and a test set of 1,322. Our chosen error metric is MAE (Mean Absolute Error), defined as: \\(\\text{MAE}_j = \\frac{1}{n_j}\\sum_{i=1}^{n_j} |y_i - \\hat{y}_i|\\)\nWe used MAE to know how well the model is performing by measuring the means of predicted and actual values. This help us evaluate and improve the model in the training stage to get more accurate prediction on new data. The advantage of used of MAE is that it is easy to interpret and understand. It is sensitive to outlier."
  },
  {
    "objectID": "project.html#implement-k-fold-cross-validation-for-k-10.",
    "href": "project.html#implement-k-fold-cross-validation-for-k-10.",
    "title": "STAT 244-SC",
    "section": "Implement k-fold cross validation for k = 10.",
    "text": "Implement k-fold cross validation for k = 10.\n\ne_commerce_fit &lt;-lm_spec %&gt;% \n  fit(unit_price~country, data = e_commerce_2011)\n\n\nmodel_1 &lt;- lm_spec%&gt;%\n fit(unit_price~country + quantity, data = e_commerce_2011)\n\nmodel_2 &lt;- lm_spec%&gt;%\n fit(unit_price ~ country * quantity+ invoice_date, data =  e_commerce_2011)\n\n\nmodel_1 %&gt;% glance()\n\n\nmodel_2 %&gt;% glance()\n\n\nmodel_1 %&gt;%\n augment(new_data =e_commerce_2011) %&gt;%\n mae(truth = unit_price, estimate = .pred)\n\n\nmodel_2 %&gt;%\n augment(new_data = e_commerce_2011) %&gt;%\n mae(truth = unit_price, estimate = .pred)\n\n\nmodel_1_cv %&gt;% collect_metrics()\n\n\nmodel_2_cv %&gt;% collect_metrics()\n\n\nmodel_1_cv %&gt;%\n  unnest(.metrics) %&gt;%\n  dplyr::filter(.metric ==\"mae\") %&gt;%\n  summarize(base::mean(.estimate))\n\n\nmodel_2_cv %&gt;%\n  unnest(.metrics) %&gt;%\n  dplyr::filter(.metric ==\"mae\") %&gt;%\n  summarize(base::mean(.estimate))\n\n\nCV: Comparing the models\n\n\n\nModel\nIN-SAMPLE MAE\n10-fold CV MAE\n\n\n\n\nmodel_1\n3.374663\n3.406162\n\n\nmodel_2\n3.400458\n3.464405\n\n\n\nBased on the in-sample MAE and CV MAE, model 1 appears to be performing little better. For model 1, it looks like the MAE is consistent it’s measured in sample (3.37) and CV (3.41). However, model 2 seem slightly higher CV MAE (3.46) than in - sample MAE(3.40), suggesting overfitting."
  },
  {
    "objectID": "project.html#loocv",
    "href": "project.html#loocv",
    "title": "STAT 244-SC",
    "section": "LOOCV",
    "text": "LOOCV\n\nLOOCV with k = n - 1\n\n# loocv for model_1, k = nrow()\nset.seed(244)\nmodel_1_loocv&lt;- lm_spec%&gt;%\n  fit_resamples(unit_price~country + quantity,\n                resamples= vfold_cv(e_commerce_2011, v = nrow(e_commerce_2011)),\n                metrics = metric_set(mae))\n\n\nmodel_1_loocv %&gt;%\n  collect_metrics()\n\n\n# loocv for model_2, k = nrow()\nset.seed(244)\nmodel_2_loocv&lt;- lm_spec%&gt;%\n  fit_resamples(unit_price ~ country * quantity + invoice_date,\n                resamples= vfold_cv(e_commerce_2011, v = nrow(e_commerce_2011)),\n                metrics = metric_set(mae))\n\n\nmodel_2_loocv %&gt;%\n  collect_metrics()\n\n\n\nLOOCV with k = 5\n\n# loocv for model_21 k = 5\n set.seed(244)\nmodel_1_LCV_5&lt;- lm_spec%&gt;%\n   fit_resamples(unit_price~country + quantity, \n       resamples= vfold_cv(e_commerce_2011, v = 5),\n       metrics = metric_set(mae)\n )\n\n\nmodel_1_LCV_5 %&gt;%\n collect_metrics()\n\n\n# lCV 5 for model_2 k = 5\nset.seed(244)\nmodel_2_LCV_5&lt;- lm_spec%&gt;%\n   fit_resamples(unit_price ~ country * quantity + invoice_date, \n       resamples= vfold_cv(e_commerce_2011, v = 5),\n       metrics = metric_set(mae)\n )\n\n\nmodel_2_LCV_5%&gt;%\n collect_metrics()\n\n\nSelect your final model based on which one has the smallest CV error.\n\n\n\n\nModel\nLOOCV MAE\n5 LOOCV MAE\n\n\n\n\nmodel_1\n3.39126\n3.419732\n\n\nmodel_2\n3.46173\n3.488275\n\n\n\nThe smallest CV error is model_1 with LOOCV MAE which ahs 3.39126\nBased on the LOOCV MAE and 5 LOOCV MAE, model 1 appears to be performing little better. For model 1, it looks like the MAE is consistent it’s measured LOOCV MAE (3.39) and 5 LOOCV MAE (3.41). However, model 2 seem slightly higher 5 LOOCV MAE (3.48) than LOOCV MAE (3.46), suggesting overfitting.\nTherefore, in CV and LOOCV, in both model 1 perform better than model 2."
  }
]